{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa621e00-5481-4ae7-b14a-61482c644d36",
   "metadata": {},
   "source": [
    "### Beamformers\n",
    "* A unified view on beamformers for M/EEG source reconstruction; Britta U. Westner, Sarang S. Dalal, Alexandre Gramfort, Vladimir Litvak, John C. Mosher, Robert Oostenveld, Jan-Mathijs Schoffelen\n",
    "\n",
    "### Source space/Sensor space \n",
    "* Ultra-Rapid serial visual presentation reveals dynamics of feedforward and feedback processes in the ventral visual pathway; Yalda Mohsenzadeh, Sheng Qin, Radoslaw M Cichy, Dimitrios Pantazis\n",
    "* MEG-based decoding of the spatiotemporal dynamics of visual category perception; M.E. van de Nieuwenhuijzen, A.R. Backus, A. Bahramisharif, C.F. Doeller, O. Jensen, M.A.J. van Gerven\n",
    "\n",
    "### Q/A\n",
    "* https://mne.discourse.group/t/best-practice-to-get-niml-gifti-or-nifti-from-stc/5767/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad1b28b-7695-4ddf-89f8-5e1212711a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "import platform\n",
    "import os\n",
    "from os import listdir\n",
    "import copy\n",
    "import ast\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io\n",
    "import nibabel\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr \n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from scipy import sparse\n",
    "from nibabel.funcs import concat_images\n",
    "from mayavi import mlab\n",
    "\n",
    "import mne\n",
    "from mne.io import read_raw_fif, read_info\n",
    "from mne.preprocessing import ICA, create_eog_epochs, create_ecg_epochs\n",
    "from mne.minimum_norm import make_inverse_operator, apply_inverse\n",
    "from mne.transforms import apply_trans\n",
    "from mne.surface import read_surface, _compute_nearest\n",
    "from mne.coreg import Coregistration\n",
    "\n",
    "matplotlib.use('Qt5Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59d0fd4-2683-42af-9c3f-cdc8cc6e78d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set intial parameters\n",
    "\n",
    "tmin = -0.1\n",
    "tmax = 0.8\n",
    "baseline = (-0.1,0)\n",
    "\n",
    "downsample_freq = 200\n",
    "powerline_freq = (50, 100, 150, 200)\n",
    "low_pass_freq = 0.05\n",
    "high_pass_freq = 330\n",
    "\n",
    "# Savitzky-Golay filter\n",
    "window_length = 25\n",
    "polyorder = 4\n",
    "# Butterworth filter\n",
    "l_freq = 0.5\n",
    "h_freq = 40\n",
    "order = 2\n",
    "\n",
    "# Number of runs\n",
    "n_runs = 12\n",
    "\n",
    "# Subject\n",
    "# Structural image not available: Subj06, Subj07, Subj10, Subj41\n",
    "# Automatic: Subj02, Subj03, Subj09, Subj10, Subj11, Subj12, Subj13, Subj14, Subj15, Subj16,\n",
    "#            Subj17, Subj18, Subj19, Subj20, Subj22, Subj23, Subj24, Subj26, Subj27, Subj28\n",
    "#            Subj29, Subj30, Subj31, Subj32, Subj34, Subj36, Subj37, Subj38, Subj39, Subj40\n",
    "#            Subj41, Subj42\n",
    "# Manual: Subj04 (EOG, ECG), Subj05 (EOG), Subj06 (EOG), Subj07 (EOG, ECG)\n",
    "# Empty room not available: Subj02, Subj03, Subj04\n",
    "# Excessive Head Motion: Subj11, Subj17, Subj22, Subj24, Subj29, Subj32\n",
    "# With oct3, ico3 for source localization: Subj28\n",
    "subj = \"Subj02\"\n",
    "\n",
    "# Events\n",
    "event_sample_list = ['N1S1TFA1', 'N1S1TFA2', 'N1S2TFA1', 'N1S2TFA2',\n",
    "                      'N1S3TFA1', 'N1S3TFA2', 'N1S4TFA1', 'N1S4TFA2',\n",
    "                      'N2S1TFA1', 'N2S1TFA2', 'N2S2TFA1', 'N2S2TFA2',\n",
    "                      'N2S3TFA1', 'N2S3TFA2', 'N2S4TFA1', 'N2S4TFA2',\n",
    "                      'N3S1TFA1', 'N3S1TFA2', 'N3S2TFA1', 'N3S2TFA2',\n",
    "                      'N3S3TFA1', 'N3S3TFA2', 'N3S4TFA1', 'N3S4TFA2',\n",
    "                      'N4S1TFA1', 'N4S1TFA2', 'N4S2TFA1', 'N4S2TFA2',\n",
    "                      'N4S3TFA1', 'N4S3TFA2', 'N4S4TFA1', 'N4S4TFA2']\n",
    "\n",
    "event_sample_dict = {'N1S1TFA1':1, 'N1S1TFA2':2, 'N1S2TFA1':3, 'N1S2TFA2':4,\n",
    "                     'N1S3TFA1':5, 'N1S3TFA2':6, 'N1S4TFA1':7, 'N1S4TFA2':8,\n",
    "                     'N2S1TFA1':9, 'N2S1TFA2':10, 'N2S2TFA1':11, 'N2S2TFA2':12,\n",
    "                     'N2S3TFA1':13, 'N2S3TFA2':14, 'N2S4TFA1':15, 'N2S4TFA2':16,\n",
    "                     'N3S1TFA1':17, 'N3S1TFA2':18, 'N3S2TFA1':19, 'N3S2TFA2':20,\n",
    "                     'N3S3TFA1':21, 'N3S3TFA2':22, 'N3S4TFA1':23, 'N3S4TFA2':24,\n",
    "                     'N4S1TFA1':25, 'N4S1TFA2':26, 'N4S2TFA1':27, 'N4S2TFA2':28,\n",
    "                     'N4S3TFA1':29, 'N4S3TFA2':30, 'N4S4TFA1':31, 'N4S4TFA2':32}\n",
    "\n",
    "event_sample_dict_N = {'N1/N1S1TFA1':1, 'N1/N1S1TFA2':2, 'N1/N1S2TFA1':3, 'N1/N1S2TFA2':4,\n",
    "                      'N1/N1S3TFA1':5, 'N1/N1S3TFA2':6, 'N1/N1S4TFA1':7, 'N1/N1S4TFA2':8,\n",
    "                      'N2/N2S1TFA1':9, 'N2/N2S1TFA2':10, 'N2/N2S2TFA1':11, 'N2/N2S2TFA2':12,\n",
    "                      'N2/N2S3TFA1':13, 'N2/N2S3TFA2':14, 'N2/N2S4TFA1':15, 'N2/N2S4TFA2':16,\n",
    "                      'N3/N3S1TFA1':17, 'N3/N3S1TFA2':18, 'N3/N3S2TFA1':19, 'N3/N3S2TFA2':20,\n",
    "                      'N3/N3S3TFA1':21, 'N3/N3S3TFA2':22, 'N3/N3S4TFA1':23, 'N3/N3S4TFA2':24,\n",
    "                      'N4/N4S1TFA1':25, 'N4/N4S1TFA2':26, 'N4/N4S2TFA1':27, 'N4/N4S2TFA2':28,\n",
    "                      'N4/N4S3TFA1':29, 'N4/N4S3TFA2':30, 'N4/N4S4TFA1':31, 'N4/N4S4TFA2':32}\n",
    "\n",
    "event_sample_dict_TFA = {'TFA1/N1S1TFA1':1, 'TFA2/N1S1TFA2':2, 'TFA1/N1S2TFA1':3, 'TFA2/N1S2TFA2':4,\n",
    "                        'TFA1/N1S3TFA1':5, 'TFA2/N1S3TFA2':6, 'TFA1/N1S4TFA1':7, 'TFA2/N1S4TFA2':8,\n",
    "                        'TFA1/N2S1TFA1':9, 'TFA2/N2S1TFA2':10, 'TFA1/N2S2TFA1':11, 'TFA2/N2S2TFA2':12,\n",
    "                        'TFA1/N2S3TFA1':13, 'TFA2/N2S3TFA2':14, 'TFA1/N2S4TFA1':15, 'TFA2/N2S4TFA2':16,\n",
    "                        'TFA1/N3S1TFA1':17, 'TFA2/N3S1TFA2':18, 'TFA1/N3S2TFA1':19, 'TFA2/N3S2TFA2':20,\n",
    "                        'TFA1/N3S3TFA1':21, 'TFA2/N3S3TFA2':22, 'TFA1/N3S4TFA1':23, 'TFA2/N3S4TFA2':24,\n",
    "                        'TFA1/N4S1TFA1':25, 'TFA2/N4S1TFA2':26, 'TFA1/N4S2TFA1':27, 'TFA2/N4S2TFA2':28,\n",
    "                        'TFA1/N4S3TFA1':29, 'TFA2/N4S3TFA2':30, 'TFA1/N4S4TFA1':31, 'TFA2/N4S4TFA2':32}\n",
    "\n",
    "event_sample_dict_S = {'S1/N1S1TFA1':1, 'S1/N1S1TFA2':2, 'S2/N1S2TFA1':3, 'S2/N1S2TFA2':4,\n",
    "                      'S3/N1S3TFA1':5, 'S3/N1S3TFA2':6, 'S4/N1S4TFA1':7, 'S4/N1S4TFA2':8,\n",
    "                      'S1/N2S1TFA1':9, 'S1/N2S1TFA2':10, 'S2/N2S2TFA1':11, 'S2/N2S2TFA2':12,\n",
    "                      'S3/N2S3TFA1':13, 'S3/N2S3TFA2':14, 'S4/N2S4TFA1':15, 'S4/N2S4TFA2':16,\n",
    "                      'S1/N3S1TFA1':17, 'S1/N3S1TFA2':18, 'S2/N3S2TFA1':19, 'S2/N3S2TFA2':20,\n",
    "                      'S3/N3S3TFA1':21, 'S3/N3S3TFA2':22, 'S4/N3S4TFA1':23, 'S4/N3S4TFA2':24,\n",
    "                      'S1/N4S1TFA1':25, 'S1/N4S1TFA2':26, 'S2/N4S2TFA1':27, 'S2/N4S2TFA2':28,\n",
    "                      'S3/N4S3TFA1':29, 'S3/N4S3TFA2':30, 'S4/N4S4TFA1':31, 'S4/N4S4TFA2':32}\n",
    "\n",
    "event_dict_N = {'N1':1, 'N2':2, 'N3':3, 'N4':4, 'Smaller Match':5, 'Larger Match':6, 'Left Button':7, 'Right Button':8}\n",
    "\n",
    "event_dict_S = {'S1':1, 'S2':2, 'S3':3, 'S4':4, 'Smaller Match':5, 'Larger Match':6, 'Left Button':7, 'Right Button':8}\n",
    "\n",
    "event_dict_TFA = {'TFA1':1, 'TFA2':2, 'Smaller Match':3, 'Larger Match':4, 'Left Button':5, 'Right Button':6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00916013-ceae-450a-8eac-c49426aa1810",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_path(subj):\n",
    "    # Check Platform\n",
    "    if platform.system() == 'Windows':\n",
    "        project_path = 'F:\\\\Data Fusion Project'\n",
    "        subject_folder = 'subject\\\\'+subj\n",
    "    elif platform.system() == 'Linux':\n",
    "        project_path = '/media/sf_Data_Fusion_Project'\n",
    "        subject_folder = 'subject/'+subj\n",
    "\n",
    "    # Tail specify the hyperparameter (e.g. ica, autoreject, smoothing, ...)\n",
    "    tail_fname = \"_ica\"+\"_savgol-\"+str(window_length)+\"-\"+str(polyorder)+\"_downsample-\"+str(downsample_freq)\n",
    "    #tail_fname = \"_ica\"+\"_butter-\"+str(order)+\"-\"+str(l_freq)+\"-\"+str(h_freq)+\"_downsample-\"+str(downsample_freq)\n",
    "    #tail_fname = \"_ica\"+\"_downsample-\"+str(downsample_freq)\n",
    "    tail_empty_fname = \"_savgol-\"+str(window_length)+\"-\"+str(polyorder)+\"_downsample-\"+str(downsample_freq)\n",
    "    #tail_empty_fname = \"_downsample-\"+str(downsample_freq)\n",
    "    raw_fname = \"raw_tsss_trans.fif\"\n",
    "    epoched_fname = \"all\"+tail_fname+\"-epo.fif\"\n",
    "    log_fname = \"log_source\"+tail_fname+\".txt\"\n",
    "    information_fname = \"information.mat\"\n",
    "    t1_fname = \"T1.mgz\"\n",
    "    transformation_fname = subj+\"-trans.fif\"\n",
    "\n",
    "    data_folder = \"data\"\n",
    "    mri_folder = \"mri\"\n",
    "    meg_folder = \"meg\"\n",
    "    figure_folder = \"fig\"\n",
    "    volume_folder = \"source\"\n",
    "    information_folder = \"information\"\n",
    "    empty_room_folder = \"empty\"\n",
    "    freesurfer_folder = \"freesurfer\"\n",
    "    fsaverage_folder = \"freesurfer\\\\fsaverage\"\n",
    "\n",
    "    mri_path = os.path.join(project_path,subject_folder,mri_folder)\n",
    "    freesurfer_path = os.path.join(project_path,subject_folder,mri_folder)\n",
    "    meg_path = os.path.join(project_path,subject_folder,meg_folder)\n",
    "    volume_path = os.path.join(project_path,subject_folder,meg_folder,volume_folder)\n",
    "    log_path = os.path.join(project_path,subject_folder,meg_folder)\n",
    "    transformation_path = os.path.join(project_path,subject_folder,meg_folder)\n",
    "    information_path = os.path.join(project_path,data_folder,information_folder)\n",
    "    empty_room_path = os.path.join(project_path,data_folder,empty_room_folder)\n",
    "    fsaverage_path = os.path.join(project_path,data_folder,fsaverage_folder)\n",
    "    figure_path = os.path.join(project_path,subject_folder,meg_folder,figure_folder)\n",
    "    \n",
    "    globals().update(locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c031ba57-ece7-49eb-911c-4efc20a5dc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_multi_image(figs,fname):\n",
    "    pdf = PdfPages(fname)\n",
    "    for fig in range(len(figs)):\n",
    "        pdf.savefig(figs[fig])\n",
    "    pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7c0f7d-c705-49aa-8277-8e087949a780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data and information\n",
    "#https://mne.tools/stable/auto_tutorials/intro/plot_10_overview.html\n",
    "\n",
    "#https://stackoverflow.com/questions/7008608/scipy-io-loadmat-nested-structures-i-e-dictionaries\n",
    "#https://stackoverflow.com/questions/59635318/load-a-mat-file-including-string-array-to-python-3-6\n",
    "\n",
    "def import_data():\n",
    "    path = os.path.join(meg_path,\"%i_\"+raw_fname)\n",
    "    raws = [read_raw_fif(path % run, verbose='error')\n",
    "            for run in range(1,n_runs+1)]  # ignore filename warnings\n",
    "    \n",
    "    return raws\n",
    "\n",
    "#--------------------------------------------------#\n",
    "\n",
    "def import_info():\n",
    "    def loadmat(filename):\n",
    "        '''\n",
    "        this function should be called instead of direct spio.loadmat\n",
    "        as it cures the problem of not properly recovering python dictionaries\n",
    "        from mat files. It calls the function check keys to cure all entries\n",
    "        which are still mat-objects\n",
    "        '''\n",
    "        def _check_keys(d):\n",
    "            '''\n",
    "            checks if entries in dictionary are mat-objects. If yes\n",
    "            todict is called to change them to nested dictionaries\n",
    "            '''\n",
    "            for key in d:\n",
    "                if isinstance(d[key], scipy.io.matlab.mio5_params.mat_struct):\n",
    "                    d[key] = _todict(d[key])\n",
    "            return d\n",
    "\n",
    "        def _todict(matobj):\n",
    "            '''\n",
    "            A recursive function which constructs from matobjects nested dictionaries\n",
    "            '''\n",
    "            d = {}\n",
    "            for strg in matobj._fieldnames:\n",
    "                elem = matobj.__dict__[strg]\n",
    "                if isinstance(elem, scipy.io.matlab.mio5_params.mat_struct):\n",
    "                    d[strg] = _todict(elem)\n",
    "                elif isinstance(elem, np.ndarray):\n",
    "                    d[strg] = _tolist(elem)\n",
    "                else:\n",
    "                    d[strg] = elem\n",
    "            return d\n",
    "\n",
    "        def _tolist(ndarray):\n",
    "            '''\n",
    "            A recursive function which constructs lists from cellarrays\n",
    "            (which are loaded as numpy ndarrays), recursing into the elements\n",
    "            if they contain matobjects.\n",
    "            '''\n",
    "            elem_list = []\n",
    "            for sub_elem in ndarray:\n",
    "                if isinstance(sub_elem, scipy.io.matlab.mio5_params.mat_struct):\n",
    "                    elem_list.append(_todict(sub_elem))\n",
    "                elif isinstance(sub_elem, np.ndarray):\n",
    "                    elem_list.append(_tolist(sub_elem))\n",
    "                else:\n",
    "                    elem_list.append(sub_elem)\n",
    "            return elem_list\n",
    "        data = scipy.io.loadmat(filename, struct_as_record=False, squeeze_me=True)\n",
    "        return _check_keys(data)\n",
    "    \n",
    "    path = os.path.join(information_path,information_fname)\n",
    "    subject_info = loadmat(path)\n",
    "    \n",
    "    return subject_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e06ebab-e56b-4e7d-9612-7f8b28fb26b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate raw objects\n",
    "# I reimplement this function from \"concatenate_raws\" in MNE because the function changed raws[0]\n",
    "#https://github.com/mne-tools/mne-python/blob/maint/0.24/mne/io/base.py#L2490-L2533\n",
    "\n",
    "def concatenate_raw_obj(raws, on_mismatch='raise'):\n",
    "    \n",
    "    from mne.io.meas_info import _ensure_infos_match\n",
    "    \n",
    "    # Make a deepcopy of raws to keep raws intact\n",
    "    #https://robertheaton.com/2014/02/09/pythons-pass-by-object-reference-as-explained-by-philip-k-dick/\n",
    "    _raws = copy.deepcopy(raws)\n",
    "    \n",
    "    for idx, r in enumerate(_raws[1:], start=1):\n",
    "        _ensure_infos_match(info1=_raws[0].info, info2=r.info, name=f'raws[{idx}]', on_mismatch=on_mismatch)\n",
    "        \n",
    "    _raws[0].append(_raws[1:])\n",
    "    \n",
    "    return _raws[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a6f0bf-0b82-4c1d-b67a-4b7170fe8ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifying raw objects\n",
    "#https://mne.tools/stable/auto_tutorials/raw/10_raw_overview.html\n",
    "\n",
    "def modify_raw_obj(raws, subject_info):\n",
    "    for r in range(1,n_runs+1):\n",
    "        drop_channels = subject_info['meg'][subj]['channels']['drop']['run'+str(r)]\n",
    "        rename_channels = subject_info['meg'][subj]['channels']['rename']['run'+str(r)]\n",
    "\n",
    "        if rename_channels != 'none':\n",
    "            channel_dict = ast.literal_eval(rename_channels)\n",
    "            for c in channel_dict.items():\n",
    "                try:\n",
    "                    raws[r-1].rename_channels(dict([c]))\n",
    "                except:\n",
    "                    raws[r-1].drop_channels(list(dict([c]).values()))\n",
    "                    raws[r-1].rename_channels(dict([c]))\n",
    "        if drop_channels != 'none':\n",
    "            raws[r-1].drop_channels(drop_channels)\n",
    "\n",
    "        if not 'EOG061' in subject_info['meg'][subj]['channels']['drop']['run'+str(r)]:\n",
    "            raws[r-1].set_channel_types({'EOG061':'eog'})\n",
    "        if not 'EOG062' in subject_info['meg'][subj]['channels']['drop']['run'+str(r)]:\n",
    "            raws[r-1].set_channel_types({'EOG062':'eog'})\n",
    "        if not 'ECG063' in subject_info['meg'][subj]['channels']['drop']['run'+str(r)]:\n",
    "            raws[r-1].set_channel_types({'ECG063':'ecg'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4a5374-1cd3-431c-a58f-0f5c03317cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating annotations programmatically - Muscle activity\n",
    "#https://mne.tools/dev/auto_examples/preprocessing/muscle_detection.html\n",
    "\n",
    "def gen_annot_muscle(raw):\n",
    "    _raw = raw.copy()\n",
    "    _raw.load_data()\n",
    "\n",
    "    # The threshold is data dependent, check the optimal threshold by plotting muscle_scores.\n",
    "    muscle_threshold = 5  # z-score\n",
    "    # Choose one channel type, if there are axial gradiometers and magnetometers\n",
    "    # Select magnetometers as they are more sensitive to muscle activity\n",
    "    muscle_annot, muscle_scores = mne.preprocessing.annotate_muscle_zscore(_raw, ch_type=\"mag\", threshold=muscle_threshold, min_length_good=0.2, filter_freq=[110, 140])\n",
    "\n",
    "    _raw.set_annotations(muscle_annot)\n",
    "    \n",
    "    return _raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0a7d2f-2199-49c8-9bda-84dbf96d08b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering data - Power line noise\n",
    "#https://mne.tools/stable/auto_tutorials/preprocessing/30_filtering_resampling.html\n",
    "\n",
    "def filter_power_noise(raw):\n",
    "    \"\"\"\n",
    "    def add_arrows(axes):\n",
    "        # add some arrows at 50 Hz and its harmonics\n",
    "        for ax in axes:\n",
    "            freqs = ax.lines[-1].get_xdata()\n",
    "            psds = ax.lines[-1].get_ydata()\n",
    "            for freq in freqs:\n",
    "                idx = np.searchsorted(freqs, freq)\n",
    "                # get ymax of a small region around the freq. of interest\n",
    "                y = psds[(idx - 4):(idx + 5)].max()\n",
    "                ax.arrow(x=freqs[idx], y=y + 18, dx=0, dy=-12, color='red',\n",
    "                         width=0.1, head_width=3, length_includes_head=True)\n",
    "    \"\"\"\n",
    "\n",
    "    _raw = raw.copy()\n",
    "    _raw.load_data()\n",
    "\n",
    "    meg_picks = mne.pick_types(_raw.info, meg=True)\n",
    "    freqs = powerline_freq\n",
    "    _raw.notch_filter(freqs=freqs, picks=meg_picks)\n",
    "    \n",
    "    return _raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a671eb9-f690-45f8-9bf2-90bc779688d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering data - Band-pass filter\n",
    "#https://mne.tools/stable/auto_tutorials/preprocessing/30_filtering_resampling.html\n",
    "#https://jasmainak.github.io/mne-workshop-brown/preprocessing/filtering.html\n",
    "\n",
    "def filter_band(raw):\n",
    "    _raw = raw.copy()\n",
    "    _raw.load_data()\n",
    "\n",
    "    meg_picks = mne.pick_types(_raw.info, meg=True)\n",
    "    _raw.filter(low_pass_freq, high_pass_freq, fir_design='firwin', picks=meg_picks)\n",
    "\n",
    "    return _raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0379df5a-e5f1-4da4-9c08-f66ff88b4592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smooth data\n",
    "#https://www.mdpi.com/1424-8220/20/3/807\n",
    "#https://www.biorxiv.org/content/10.1101/731687v1.full\n",
    "#https://brainder.org/2011/08/20/gaussian-kernels-convert-fwhm-to-sigma/\n",
    "#https://www.delftstack.com/howto/python/smooth-data-in-python/    \n",
    "\n",
    "def smooth_savgol_raw(raw):\n",
    "    #Savitzky-Golay filter\n",
    "    def savgol(x):\n",
    "        return scipy.signal.savgol_filter(x,window_length,polyorder)\n",
    "\n",
    "    _raw = raw.copy()\n",
    "    _raw.load_data()\n",
    "\n",
    "    meg_picks = mne.pick_types(_raw.info, meg=True)\n",
    "    _raw.apply_function(savgol, picks=meg_picks, dtype=None, n_jobs=1, channel_wise=True)\n",
    "\n",
    "    return _raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e9d884-7971-4037-b237-9b9afc6de66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smooth data (Butterworth Filter)\n",
    "#https://mne.discourse.group/t/butterworth-filter/5760\n",
    "\n",
    "def smooth_butter_raw(raw):\n",
    "    _raw = raw.copy()\n",
    "    _raw.load_data()\n",
    "\n",
    "    iir_params = dict(order=order, ftype='butter')\n",
    "    meg_picks = mne.pick_types(_raw.info, meg=True)\n",
    "    _raw.filter(l_freq=l_freq, h_freq=h_freq, picks=meg_picks, method='iir', iir_params=iir_params, verbose=True)\n",
    "\n",
    "    return _raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd97673-ed4b-444a-9af9-4197b1a11161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsampling\n",
    "#https://mne.tools/stable/auto_tutorials/preprocessing/30_filtering_resampling.html\n",
    "#https://jasmainak.github.io/mne-workshop-brown/preprocessing/filtering.html\n",
    "\n",
    "def downsample_raw(raw):\n",
    "    #raw.resample(120,npad=\"auto\") # set sampling frequency to 120Hz\n",
    "\n",
    "    current_sfreq = raw.info['sfreq']\n",
    "    desired_sfreq = downsample_freq\n",
    "    decim = np.round(current_sfreq / desired_sfreq).astype(int)\n",
    "    obtained_sfreq = current_sfreq / decim\n",
    "    lowpass_freq = obtained_sfreq / 3.\n",
    "\n",
    "    _raw = raw.copy()\n",
    "    _raw.load_data()\n",
    "\n",
    "    _raw.filter(l_freq=None, h_freq=lowpass_freq)\n",
    "\n",
    "    return _raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cca35a9-4d3c-4478-8192-26f4a4be1bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repairing artifacts with ICA\n",
    "#https://mne.tools/stable/auto_tutorials/preprocessing/40_artifact_correction_ica.html\n",
    "#https://labeling.ucsd.edu/tutorial/labels\n",
    "\n",
    "def fit_ica(raw,r):\n",
    "    figs = []\n",
    "\n",
    "    # Filtering to remove slow drifts\n",
    "    # As filtering is a linear operation, the ICA solution found from the filtered signal can be applied to the unfiltered signal\n",
    "    _raw = raw.copy()\n",
    "    _raw.load_data().filter(l_freq=1., h_freq=None)\n",
    "\n",
    "    # Estimate noise covariance matrix from a continuous segment of raw data.\n",
    "    # It is typically useful to estimate a noise covariance from empty room data or time intervals before starting the stimulation.\n",
    "    #noise_cov = mne.compute_raw_covariance(raw_erm, tmin=0, tmax=None)\n",
    "\n",
    "    # Fitting the ICA solution\n",
    "    ica = ICA(n_components=30, max_iter=1000, random_state=97, method='picard')\n",
    "    #ica = ICA(n_components=15, max_iter=1000, random_state=97, method='picard', noise_cov=noise_cov)\n",
    "    ica.fit(_raw)\n",
    "    \n",
    "    figs.append(ica.plot_sources(raw, show_scrollbars=False))\n",
    "    figs.append(ica.plot_components(picks=slice(0,30,1)))\n",
    "\n",
    "    ecg_idx = mne.pick_types(raw.info, meg=False, eeg=False, stim=False,\n",
    "                             eog=False, ecg=True, emg=False, ref_meg=False,\n",
    "                             exclude='bads')\n",
    "    \n",
    "    eog_idx = mne.pick_types(raw.info, meg=False, eeg=False, stim=False,\n",
    "                             eog=True, ecg=False, emg=False, ref_meg=False,\n",
    "                             exclude='bads')\n",
    "    \n",
    "    if list(ecg_idx)!=[]:\n",
    "        ecg_evoked = create_ecg_epochs(raw).average()\n",
    "        ecg_evoked.apply_baseline(baseline=(None, -0.2))\n",
    "        ecg_indices, ecg_scores = ica.find_bads_ecg(raw, method='correlation', threshold='auto')\n",
    "        ecgAvailable = True\n",
    "    else:\n",
    "        ecgAvailable = False\n",
    "    \n",
    "    if eog_idx!=[]:\n",
    "        eog_evoked = create_eog_epochs(raw).average()\n",
    "        eog_evoked.apply_baseline(baseline=(None, -0.2))\n",
    "        eog_indices, eog_scores = ica.find_bads_eog(raw)\n",
    "        eogAvailable = True\n",
    "    else:\n",
    "        eogAvailable = False\n",
    "\n",
    "    # Save figures temporarily for inspection\n",
    "    fname=str(r+1)+'_temp_figs.pdf'\n",
    "    save_multi_image(figs,os.path.join(figure_path,fname))\n",
    "    matplotlib.pyplot.close('all')\n",
    "        \n",
    "    # If EOG channels are not available, user should select the components manually\n",
    "    if not eogAvailable:\n",
    "        eog_indices = []\n",
    "        print(\"EOG was not available, consequently, please select the EOG components manually!\")\n",
    "        n = int(input(\"Please enter the number of EOG component(s) you want to exclude (RUN \"+str(r+1) +\"): \"))\n",
    "        for i in range(n):\n",
    "            eog_indices.append(int(input(\"Please enter the index of the  EOG component(s) you want to exclude one by one: \")))\n",
    "            \n",
    "    # If ECG channel is not available, user should select the components manually\n",
    "    if not ecgAvailable:\n",
    "        ecg_indices = []\n",
    "        print(\"ECG was not available, consequently, please select the ECG components manually!\")\n",
    "        n = int(input(\"Please enter the number of ECG component(s) you want to exclude (RUN \"+str(r+1) +\"): \"))\n",
    "        for i in range(n):\n",
    "            ecg_indices.append(int(input(\"Please enter the index of the ECG component(s) you want to exclude one by one: \")))\n",
    "            \n",
    "    # Delete temporary figures\n",
    "    os.remove(os.path.join(figure_path,fname))\n",
    "\n",
    "    if eogAvailable and eog_indices!=[]:\n",
    "        ica.exclude = []\n",
    "        ica.exclude = eog_indices\n",
    "\n",
    "        # Barplot of ICA component \"EOG match\" scores\n",
    "        figs.append(ica.plot_scores(eog_scores))\n",
    "\n",
    "        # Plot diagnostics\n",
    "        figs = figs + ica.plot_properties(raw, picks=eog_indices)\n",
    "\n",
    "        # Plot ICs applied to raw data, with EOG matches highlighted\n",
    "        figs.append(ica.plot_sources(raw, show_scrollbars=False))\n",
    "\n",
    "        # Plot ICs applied to the averaged EOG epochs, with EOG matches highlighted\n",
    "        figs.append(ica.plot_sources(eog_evoked))\n",
    "\n",
    "        ica.exclude = []\n",
    "        try:\n",
    "            eog_index = [eog_indices[0]]\n",
    "        except:\n",
    "            eog_index = [eog_indices]\n",
    "    elif eog_indices==[]:\n",
    "        eog_index = []\n",
    "    else:\n",
    "        try:\n",
    "            eog_index = [eog_indices[0]]\n",
    "        except:\n",
    "            eog_index = [eog_indices]\n",
    "\n",
    "    if ecgAvailable and ecg_indices!=[]:\n",
    "        ica.exclude = []\n",
    "        ica.exclude = ecg_indices\n",
    "\n",
    "        # Barplot of ICA component \"ECG match\" scores\n",
    "        figs.append(ica.plot_scores(ecg_scores))\n",
    "\n",
    "        # Plot diagnostics\n",
    "        figs = figs + ica.plot_properties(raw, picks=ecg_indices)\n",
    "\n",
    "        # Plot ICs applied to raw data, with ECG matches highlighted\n",
    "        figs.append(ica.plot_sources(raw, show_scrollbars=False))\n",
    "\n",
    "        # Plot ICs applied to the averaged ECG epochs, with ECG matches highlighted\n",
    "        figs.append(ica.plot_sources(ecg_evoked))\n",
    "\n",
    "        ica.exclude = []\n",
    "        try:\n",
    "            ecg_index = [ecg_indices[0]]\n",
    "        except:\n",
    "            ecg_index = [ecg_indices]\n",
    "    elif ecg_indices==[]:\n",
    "        ecg_index = []\n",
    "    else:\n",
    "        try:\n",
    "            ecg_index = [ecg_indices[0]]\n",
    "        except:\n",
    "            ecg_index = [ecg_indices]\n",
    "\n",
    "    # Exclude only the first components\n",
    "    ica.exclude = eog_index+ecg_index\n",
    "    print(\"EOG index \"+str(eog_index)+\" was removed!\")\n",
    "    print(\"ECG index \"+str(ecg_index)+\" was removed!\")\n",
    "\n",
    "    if ica.exclude!=[]:\n",
    "        _raw = raw.copy()\n",
    "        _raw.load_data()\n",
    "        ica.apply(_raw)\n",
    "\n",
    "        #fname=str(r+1)+'_components'+tail_fname+'.pdf'\n",
    "        #save_multi_image(figs,os.path.join(figure_path,fname))\n",
    "        matplotlib.pyplot.close('all')\n",
    "    else:\n",
    "        _raw = raw.copy()\n",
    "        \n",
    "        #fname=str(r+1)+'_components'+tail_fname+'.pdf'\n",
    "        #save_multi_image(figs,os.path.join(figure_path,fname))\n",
    "        matplotlib.pyplot.close('all')\n",
    "\n",
    "    return _raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c230d0-9c12-4b83-b32c-f6120f0784dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make experimental events\n",
    "#https://mne.tools/stable/auto_tutorials/intro/plot_10_overview.html\n",
    "#https://mne.tools/dev/auto_tutorials/raw/plot_20_event_arrays.html\n",
    "\n",
    "def make_event(raw):\n",
    "    # Sample Stimulus: 1-32\n",
    "    # Smaller Match Stimulus: 1-32 + 32\n",
    "    # Larger Match Stimulus: 1-32 + 64\n",
    "    # Button Pressed: 1,2,4,8 + 128\n",
    "    # Right Hand: Yellow (2), Green (4)\n",
    "    # Left Hand: Red (1), Blue (8)\n",
    "    # 4 comparision in each block (2 larger, 2 smaller)\n",
    "    # 16 comarision in each fif files (8 larger, 8 smaller)\n",
    "    \n",
    "    _raw = raw.copy()\n",
    "    events = mne.find_events(_raw, stim_channel='STI101', min_duration=.005, shortest_event=1, output='onset')\n",
    "\n",
    "    # Merged events for number\n",
    "    merged_events_num = events\n",
    "    merged_events_num = mne.merge_events(merged_events_num, list(range(1,9)), 1)   #N1\n",
    "    merged_events_num = mne.merge_events(merged_events_num, list(range(9,17)), 2)   #N2\n",
    "    merged_events_num = mne.merge_events(merged_events_num, list(range(17,25)), 3)   #N3\n",
    "    merged_events_num = mne.merge_events(merged_events_num, list(range(25,33)), 4)   #N4\n",
    "    merged_events_num = mne.merge_events(merged_events_num, list(range(33,65)), 5)   #Smaller Match\n",
    "    merged_events_num = mne.merge_events(merged_events_num, list(range(65,129)), 6)   #Larger Match\n",
    "    merged_events_num = mne.merge_events(merged_events_num, [129,136], 7)   #Left Button\n",
    "    merged_events_num = mne.merge_events(merged_events_num, [130,132], 8)   #Right Button\n",
    "\n",
    "    # Merged events for size\n",
    "    merged_events_size = events\n",
    "    merged_events_size = mne.merge_events(merged_events_size, [1,2,9,10,17,18,25,26], 1)   #S1\n",
    "    merged_events_size = mne.merge_events(merged_events_size, [3,4,11,12,19,20,27,28], 2)   #S2\n",
    "    merged_events_size = mne.merge_events(merged_events_size, [5,6,13,14,21,22,29,30], 3)   #S3\n",
    "    merged_events_size = mne.merge_events(merged_events_size, [7,8,15,16,23,24,31,32], 4)   #S4\n",
    "    merged_events_size = mne.merge_events(merged_events_size, list(range(33,65)), 5)   #Smaller Match\n",
    "    merged_events_size = mne.merge_events(merged_events_size, list(range(65,129)), 6)   #Larger Match\n",
    "    merged_events_size = mne.merge_events(merged_events_size, [129,136], 7)   #Left Button\n",
    "    merged_events_size = mne.merge_events(merged_events_size, [130,132], 8)   #Right Button\n",
    "\n",
    "    # Merged events for TFA\n",
    "    merged_events_tfa = events\n",
    "    merged_events_tfa = mne.merge_events(merged_events_tfa, [1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31], 1)   #TFA1\n",
    "    merged_events_tfa = mne.merge_events(merged_events_tfa, [2,4,6,8,10,12,14,16,18,20,22,24,26,28,30,32], 2)   #TFA2\n",
    "    merged_events_tfa = mne.merge_events(merged_events_tfa, list(range(33,65)), 3)   #Smaller Match\n",
    "    merged_events_tfa = mne.merge_events(merged_events_tfa, list(range(65,129)), 4)   #Larger Match\n",
    "    merged_events_tfa = mne.merge_events(merged_events_tfa, [129,136], 5)   #Left Button\n",
    "    merged_events_tfa = mne.merge_events(merged_events_tfa, [130,132], 6)   #Right Button\n",
    "\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eacf7b5-8064-45e8-b949-d7b1d274dd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoch the data\n",
    "#https://mne.tools/stable/auto_tutorials/intro/plot_10_overview.html\n",
    "#https://mne.tools/stable/auto_tutorials/preprocessing/20_rejecting_bad_data.html\n",
    "#https://www.fieldtriptoolbox.org/tutorial/visual_artifact_rejection/\n",
    "#https://mne.tools/stable/auto_tutorials/preprocessing/30_filtering_resampling.html\n",
    "\n",
    "def epoch_data(events,raw):\n",
    "    \n",
    "    current_sfreq = raw.info['sfreq']\n",
    "    desired_sfreq = downsample_freq\n",
    "    decim = np.round(current_sfreq / desired_sfreq).astype(int)\n",
    "    \n",
    "    \"\"\"\n",
    "    # Reject criteria\n",
    "    reject_criteria = dict(mag=4000e-15,     # 4000 fT\n",
    "                           grad=4000e-13)    # 4000 fT/cm\n",
    "\n",
    "    # Flat criteria\n",
    "    flat_criteria = dict(mag=1e-15,          # 1 fT\n",
    "                         grad=1e-13)         # 1 fT/cm\n",
    "\n",
    "    # Epochs with rejecting criteria and annotation\n",
    "    epochs_sample_N = mne.Epochs(raw, events, event_id=event_sample_dict_N,\n",
    "                                 baseline=baseline, tmin=tmin, tmax=tmax, decim=decim, \n",
    "                                 reject=reject_criteria, flat=flat_criteria,\n",
    "                                 reject_by_annotation=True,\n",
    "                                 preload=True)\n",
    "\n",
    "    # Epochs with rejecting annotation\n",
    "    epochs_sample_N = mne.Epochs(raw, events, event_id=event_sample_dict_N,\n",
    "                                 baseline=baseline, tmin=tmin, tmax=tmax, decim=decim, \n",
    "                                 reject_by_annotation=True,\n",
    "                                 preload=True)\n",
    "    \"\"\"\n",
    "\n",
    "    # Epochs without rejecting criteria and annotation\n",
    "    epochs_sample_all = mne.Epochs(raw, events, event_id=event_sample_dict,\n",
    "                                 baseline=baseline, tmin=tmin, tmax=tmax, decim=decim)\n",
    "    \n",
    "    epochs = {\"all\": epochs_sample_all}\n",
    "\n",
    "    return epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebcdda2-13e8-40fc-a644-244970c44009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FreeSurfer MRI reconstruction\n",
    "#https://mne.tools/stable/auto_tutorials/source-modeling/plot_background_freesurfer.html\n",
    "\n",
    "def reconstruct_mri():\n",
    "    Brain = mne.viz.get_brain_class()\n",
    "    brain = Brain(freesurfer_folder, hemi='lh', surf='pial', subjects_dir=mri_path, size=(800, 600))\n",
    "    brain.add_annotation('aparc.a2009s', borders=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a39efc-981e-4a0a-a72d-04cd6b3dadcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize MRI coordinate frames\n",
    "#https://mne.tools/stable/auto_tutorials/source-modeling/plot_background_freesurfer_mne.html\n",
    "\n",
    "def visualize_mri():\n",
    "    t1 = nibabel.load(os.path.join(mri_path, freesurfer_folder, 'mri', t1_fname))\n",
    "    t1.orthoview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf4293d-e1de-4563-ae07-278847879fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make BEM\n",
    "#https://mne.tools/stable/auto_tutorials/source-modeling/plot_forward.html\n",
    "\n",
    "# Before running the following command, run the following commands\n",
    "# Run the following commands in the same command window that anaconda has been launched\n",
    "#export FREESURFER_HOME=/home/ali/FreeSurfer\n",
    "#source $FREESURFER_HOME/SetUpFreeSurfer.sh\n",
    "\n",
    "def make_bem(path_to_freesurfer):\n",
    "    mne.bem.make_watershed_bem(freesurfer_folder, subjects_dir=path_to_freesurfer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acca485-1d4b-4920-ac4a-5d6ee9c57531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize BEM\n",
    "#https://mne.tools/stable/auto_tutorials/source-modeling/plot_forward.html\n",
    "\n",
    "def visualize_bem():\n",
    "    mne.viz.plot_bem(subject=freesurfer_folder, subjects_dir=mri_path, brain_surfaces='white', orientation='coronal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3df911-fc15-43d7-9851-2e00e7e33134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Coregistration (GUI)\n",
    "#https://pybrain-workshop.github.io/\n",
    "#https://mne.tools/stable/auto_tutorials/source-modeling/plot_source_alignment.html\n",
    "#https://www.slideshare.net/mne-python/mnepython-coregistration\n",
    "#https://www.youtube.com/watch?v=ALV5qqMHLlQ&t=6s\n",
    "#https://mne-cpp.github.io/pages/documentation/analyze_coregistration.html\n",
    "\n",
    "def make_coregistration_gui(epoch):\n",
    "    trans = os.path.join(transformation_path,transformation_fname)\n",
    "    mne.gui.coregistration(freesurfer_folder, subjects_dir=mri_path, inst=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6eeaaef-2fc6-4f47-a547-ef207ff2b3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Coregistration (Automatic)\n",
    "#https://mne.tools/stable/auto_tutorials/forward/25_automated_coreg.html\n",
    "\n",
    "def make_coregistration_automatic(epoch):\n",
    "    \n",
    "    plot_kwargs = dict(subject=freesurfer_folder, subjects_dir=mri_path,\n",
    "                   surfaces=\"head\", dig=True, eeg=[],\n",
    "                   meg='sensors', show_axes=True,\n",
    "                   coord_frame='meg')\n",
    "    view_kwargs = dict(elevation=90, distance=0.6,\n",
    "                       focalpoint=(0., 0., 0.))\n",
    "\n",
    "    # Set up the coregistration model\n",
    "    info = read_info(epoch)\n",
    "    fiducials = \"auto\"  # get fiducials from subject\n",
    "    coreg = Coregistration(info, subject=freesurfer_folder, subjects_dir=mri_path, fiducials=fiducials)\n",
    "    #fig = mne.viz.plot_alignment(info, trans=coreg.trans, **plot_kwargs)\n",
    "\n",
    "    # Initial fit with fiducials\n",
    "    coreg.fit_fiducials(verbose=True)\n",
    "    #fig = mne.viz.plot_alignment(info, trans=coreg.trans, **plot_kwargs)\n",
    "\n",
    "    # Refining with ICP\n",
    "    coreg.fit_icp(n_iterations=20, nasion_weight=10, verbose=True)\n",
    "    #fig = mne.viz.plot_alignment(info, trans=coreg.trans, **plot_kwargs)\n",
    "\n",
    "    # Omitting bad points\n",
    "    coreg.omit_head_shape_points(distance=5. / 1000)  # distance is in meters\n",
    "\n",
    "    # Final coregistration fit\n",
    "    coreg.fit_icp(n_iterations=20, nasion_weight=10., verbose=True)\n",
    "    \n",
    "    # https://mne.discourse.group/t/how-to-save-plot-sensors-connectivity/4958/4\n",
    "    fig = mne.viz.plot_alignment(info, trans=coreg.trans, **plot_kwargs)\n",
    "    mne.viz.set_3d_view(fig, azimuth=90, **view_kwargs)\n",
    "    screenshot = fig.plotter.screenshot()\n",
    "    fig_temp, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.imshow(screenshot, origin='upper')\n",
    "    ax.set_axis_off()  # Disable axis labels and ticks\n",
    "    fig_temp.tight_layout()\n",
    "    fig_temp.savefig(os.path.join(figure_path,'coregistration_90.png'), dpi=150)\n",
    "    matplotlib.pyplot.close('all')\n",
    "    \n",
    "    fig = mne.viz.plot_alignment(info, trans=coreg.trans, **plot_kwargs)\n",
    "    mne.viz.set_3d_view(fig, azimuth=45, **view_kwargs)\n",
    "    screenshot = fig.plotter.screenshot()\n",
    "    fig_temp, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.imshow(screenshot, origin='upper')\n",
    "    ax.set_axis_off()  # Disable axis labels and ticks\n",
    "    fig_temp.tight_layout()\n",
    "    fig_temp.savefig(os.path.join(figure_path,'coregistration_45.png'), dpi=150)\n",
    "    matplotlib.pyplot.close('all')\n",
    "    \n",
    "    fig = mne.viz.plot_alignment(info, trans=coreg.trans, **plot_kwargs)\n",
    "    mne.viz.set_3d_view(fig, azimuth=0, **view_kwargs)\n",
    "    screenshot = fig.plotter.screenshot()\n",
    "    fig_temp, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.imshow(screenshot, origin='upper')\n",
    "    ax.set_axis_off()  # Disable axis labels and ticks\n",
    "    fig_temp.tight_layout()\n",
    "    fig_temp.savefig(os.path.join(figure_path,'coregistration_0.png'), dpi=150)\n",
    "    matplotlib.pyplot.close('all')\n",
    "    \n",
    "    dists = coreg.compute_dig_mri_distances() * 1e3  # in mm\n",
    "    print(\n",
    "        f\"Distance between HSP and MRI (mean/min/max):\\n{np.mean(dists):.2f} mm \"\n",
    "        f\"/ {np.min(dists):.2f} mm / {np.max(dists):.2f} mm\"\n",
    "    )\n",
    "\n",
    "    # Save the file\n",
    "    mne.write_trans(meg_path+'\\\\'+transformation_fname, coreg.trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e9d7df-b7f3-45bc-93e3-532ace5fd2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Coregistration\n",
    "#https://mne.tools/stable/auto_tutorials/source-modeling/plot_source_alignment.html\n",
    "#https://mne.tools/stable/auto_tutorials/source-modeling/plot_forward.html\n",
    "\n",
    "def visualize_coregistration(epoch):\n",
    "    # The transformation file obtained by coregistration\n",
    "    trans = os.path.join(transformation_path,transformation_fname)\n",
    "    info = mne.io.read_info(epoch)\n",
    "\n",
    "    mne.viz.plot_alignment(info, trans, freesurfer_folder, subjects_dir=mri_path, dig=True, meg=['helmet', 'sensors'], surfaces='outer_skull')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ed74ce-f001-48c6-85a2-e7bea9dc7b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computing a Covariance Matrix from Baseline\n",
    "#https://mne.tools/stable/auto_tutorials/forward/90_compute_covariance.html\n",
    "\n",
    "def make_cov_baseline(figure_path,event_fname,epoch):\n",
    "    figs = []\n",
    "    \n",
    "    noise_cov = mne.compute_covariance(epoch, tmax=0)\n",
    "    \n",
    "    fig = noise_cov.plot(epoch.info, proj=True);\n",
    "    figs.append(fig[0])\n",
    "    figs.append(fig[1])\n",
    "    save_multi_image(figs,os.path.join(figure_path+'\\\\'+f\"cov_matrix_{event_fname}{tail_fname}.pdf\"))\n",
    "    matplotlib.pyplot.close('all')\n",
    "    \n",
    "    return noise_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1cc703-5351-4aaa-a709-dff8da44a07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computing a Covariance Matrix from Empty Room\n",
    "#https://mne.tools/stable/auto_tutorials/forward/90_compute_covariance.html\n",
    "\n",
    "def make_cov_empty(raw_empty_room,raw_empty_room_fname):\n",
    "    figs = []\n",
    "    \n",
    "    noise_cov = mne.compute_raw_covariance(raw_empty_room, tmin=0, tmax=None)\n",
    "    mne.write_cov(os.path.join(empty_room_path, raw_empty_room_fname.replace('.fif',tail_empty_fname+'_cov.fif.gz')),noise_cov)\n",
    "    \n",
    "    fig = noise_cov.plot(raw_empty_room.info, proj=True);\n",
    "    figs.append(fig[0])\n",
    "    figs.append(fig[1])\n",
    "    save_multi_image(figs,os.path.join(empty_room_path,raw_empty_room_fname.replace('.fif',tail_empty_fname+'.pdf')))\n",
    "    matplotlib.pyplot.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b47ad2f-c5f4-4164-9594-29c37a3241e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading a Covariance Matrix from Empty Room\n",
    "#https://mne.tools/stable/auto_tutorials/forward/90_compute_covariance.html\n",
    "\n",
    "def read_cov_empty(subject_info):    \n",
    "    raw_empty_room_fname = subject_info['meg'][subj]['empty']+tail_empty_fname+\"_cov.fif.gz\"\n",
    "    noise_cov = mne.read_cov(os.path.join(empty_room_path, raw_empty_room_fname))\n",
    "    \n",
    "    return noise_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973632cf-87e9-4b19-85a2-2f77cb02a108",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Source Localization\n",
    "#https://mne.tools/stable/auto_tutorials/inverse/30_mne_dspm_loreta.html\n",
    "\n",
    "def make_source_localization(epoch,evoked,noise_cov):\n",
    "    trans = os.path.join(transformation_path,transformation_fname)\n",
    "    src = mne.setup_source_space(subject='freesurfer', spacing='oct4', add_dist='patch', surface='white', subjects_dir=mri_path)\n",
    "    model = mne.make_bem_model(subject='freesurfer', ico=4, conductivity=(0.3,), subjects_dir=mri_path)\n",
    "    bem = mne.make_bem_solution(model)\n",
    "    fwd = mne.make_forward_solution(epoch.info, trans=trans, src=src, bem=bem, meg=True, eeg=False, mindist=5.0, n_jobs=1, verbose=True)\n",
    "    inverse_operator = make_inverse_operator(evoked.info, fwd, noise_cov, loose=1, depth=None, verbose=True)\n",
    "    del fwd\n",
    "    \n",
    "    method = \"dSPM\"\n",
    "    snr = 3.\n",
    "    lambda2 = 1. / snr ** 2\n",
    "    stc= apply_inverse(evoked, inverse_operator, lambda2, method=method, pick_ori=None, verbose=True)\n",
    "    #src = inverse_operator['src']\n",
    "    \n",
    "    return stc, src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77aaa59-4256-465f-ace2-0ed3c425e795",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize Source Localization\n",
    "#https://mne.tools/stable/auto_tutorials/inverse/30_mne_dspm_loreta.html\n",
    "#https://mne.tools/stable/auto_tutorials/inverse/60_visualize_stc.html\n",
    "\n",
    "def visualize_source_localization(stc,hemi):\n",
    "    vertno_max, time_max = stc.get_peak(hemi=hemi)\n",
    "    surfer_kwargs = dict(hemi=hemi, subjects_dir=mri_path, clim=dict(kind='value', lims=[5, 95, 185]), \n",
    "                         views='lateral', initial_time=0, time_unit='s', size=(800, 800), smoothing_steps=15)\n",
    "\n",
    "    brain = stc.plot(**surfer_kwargs)\n",
    "    brain.add_foci(vertno_max, coords_as_verts=True, hemi=hemi, color='blue', scale_factor=0.6, alpha=0.5)\n",
    "    brain.add_text(0.1, 0.9, 'dSPM (plus location of maximal activation)', 'title', font_size=14)\n",
    "    #brain.save_movie(time_dilation=20, tmin=0.05, tmax=0.16, interpolation='linear', framerate=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd941cd-debe-4f46-a5dd-a5da18ab48d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize Source Localization (Morph)\n",
    "#https://mne.tools/stable/auto_tutorials/inverse/30_mne_dspm_loreta.html\n",
    "#https://mne.tools/stable/auto_tutorials/inverse/60_visualize_stc.html\n",
    "\n",
    "def visualize_source_localization_morph(stc):\n",
    "    stc_fs = mne.compute_source_morph(stc, 'freesurfer', fsaverage_path, mri_path, smooth=15, verbose='error').apply(stc)\n",
    "    brain = stc_fs.plot(subjects_dir=mri_path, initial_time=0,\n",
    "                    clim=dict(kind='value', lims=[5, 95, 185]),\n",
    "                    surface='flat', hemi='both', size=(1000, 500),\n",
    "                    smoothing_steps=15, time_viewer=True,\n",
    "                    add_data_kwargs=dict(colorbar_kwargs=dict(label_font_size=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5a7ba1-77be-4386-ba9d-523a5e68d571",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exporting Surface Sources as NIfTI Volume\n",
    "#https://mne.discourse.group/t/exporting-surface-sources-as-nifti-volume/5518\n",
    "\n",
    "def save_surface_src_volume(stc, subject, subjects_dir, time_downsample_factor, save_file_name):\n",
    "    n_vertices = sum(len(v) for v in stc.vertices)\n",
    "    offset = 0\n",
    "    surf_to_mri = 0.\n",
    "    for hi, hemi in enumerate(['lh', 'rh']):\n",
    "        ribbon = nib.load(Path(subjects_dir / subject / 'mri' / f'{hemi}.ribbon.mgz'))\n",
    "        xfm = ribbon.header.get_vox2ras_tkr()\n",
    "        mri_data = np.asanyarray(ribbon.dataobj)\n",
    "        ijk = np.array(np.where(mri_data)).T\n",
    "        xyz = apply_trans(xfm, ijk) / 1000.\n",
    "        row_ind = np.where(mri_data.ravel())[0]\n",
    "        data = np.ones(row_ind.size)\n",
    "        rr = read_surface(Path(subjects_dir / subject / 'surf'/ f'{hemi}.white'))[0]\n",
    "        rr /= 1000.\n",
    "        rr = rr[stc.vertices[hi]]\n",
    "        col_ind = _compute_nearest(rr, xyz) + offset\n",
    "        surf_to_mri = surf_to_mri + sparse.csr_matrix(\n",
    "            (data, (row_ind, col_ind)), shape=(mri_data.size, n_vertices))\n",
    "        offset += len(stc.vertices[hi])\n",
    "\n",
    "    source_data = xr.DataArray(stc.data, dims=[\"sources\", \"time\"]) \\\n",
    "                    .rolling(time=time_downsample_factor, center=True) \\\n",
    "                    .mean()[:, time_downsample_factor//2:-time_downsample_factor//2:time_downsample_factor]\n",
    "\n",
    "    data_all_times = []\n",
    "    for time_data in source_data.transpose(\"time\", \"sources\").values:\n",
    "        data = surf_to_mri.dot(time_data)\n",
    "        data = data.reshape(mri_data.shape).astype(\"float32\")\n",
    "        data_all_times.append(nib.Nifti1Image(data, ribbon.affine))\n",
    "\n",
    "    nib.save(concat_images(data_all_times), save_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321cb021-b20d-4e57-863d-314c503a667e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "########## Make BEM ##########\n",
    "subject_list = ['Subj02','Subj03','subj04','Subj05','Subj09','Subj11',\n",
    "                'Subj12','Subj13','Subj14','Subj15','Subj16','Subj17',\n",
    "                'Subj18','Subj19','Subj20','Subj22','Subj23','Subj24',\n",
    "                'Subj26','Subj27','Subj28','Subj29','Subj30','Subj31',\n",
    "                'Subj32','Subj34','Subj36','Subj37','Subj38','Subj39',\n",
    "                'Subj40','Subj42']\n",
    "\n",
    "for subj in subject_list:\n",
    "    set_path(subj)\n",
    "    make_bem(freesurfer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449517aa-f81a-486f-a387-1b67b82f6042",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "########## Make Noise Covariance ##########\n",
    "empty_file_list = []\n",
    "for file in listdir(empty_room_path+'\\\\raw'):\n",
    "    if file.endswith('.fif'):\n",
    "        empty_file_list.append(file)\n",
    "\n",
    "for f in empty_file_list:\n",
    "    empty_file = mne.io.read_raw_fif(os.path.join(empty_room_path+'\\\\raw', f))\n",
    "    \n",
    "    ########## Filter Data ########## \n",
    "    empty_file = filter_power_noise(empty_file)\n",
    "    empty_file = filter_band(empty_file)\n",
    "    ########## Smooth Data ########## \n",
    "    empty_file = smooth_savgol_raw(empty_file)\n",
    "    #empty_file = smooth_butter_raw(empty_file)\n",
    "    ########## Downsample Data ########## \n",
    "    empty_file = downsample_raw(empty_file)\n",
    "    ########## Pick MEG ##########\n",
    "    empty_file.pick_types(meg=True, eeg=False, stim=False, misc=False, eog=False, ecg=False, include=[], exclude=[])\n",
    "    \n",
    "    make_cov_empty(empty_file,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c682b34-2999-41eb-86d4-ae0c5cb3dcf4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "########## Import Data and Information ########## \n",
    "set_path(subj)\n",
    "raws = import_data()\n",
    "subject_info = import_info()\n",
    "modify_raw_obj(raws,subject_info)\n",
    "\n",
    "for r in range(n_runs):\n",
    "    ########## Filter Data ########## \n",
    "    print(\"************************* Power-line noise filter - run: \"+str(r+1)+\" *************************\")\n",
    "    raws[r] = filter_power_noise(raws[r])\n",
    "\n",
    "    print(\"************************* Band-pass filter - run: \"+str(r+1)+\" *************************\")\n",
    "    raws[r] = filter_band(raws[r])\n",
    "    \n",
    "    ########## Run ICA ########## \n",
    "    if \"ica\" in tail_fname:\n",
    "        print(\"************************* Run ICA - run: \"+str(r+1)+\" *************************\")\n",
    "        raws[r] = fit_ica(raws[r],r)\n",
    "    \n",
    "    ########## Annotate Muscle ########## \n",
    "    print(\"************************* Annotate muscle activity - run: \"+str(r+1)+\" *************************\")\n",
    "    raws[r] = gen_annot_muscle(raws[r])\n",
    "\n",
    "    ########## Smooth Data ########## \n",
    "    print(\"************************* Smooth data - run: \"+str(r+1)+\" *************************\")\n",
    "    raws[r] = smooth_savgol_raw(raws[r])\n",
    "    #raws[r] = smooth_butter_raw(raws[r])\n",
    "\n",
    "    ########## Downsample Data ########## \n",
    "    print(\"************************* Downsample data - run: \"+str(r+1)+\" *************************\")\n",
    "    raws[r] = downsample_raw(raws[r])\n",
    "    \n",
    "    ########## Pick MEG ##########\n",
    "    raws[r].pick_types(meg=True, eeg=False, stim=True, misc=True, eog=False, ecg=False, include=[], exclude=[])\n",
    "\n",
    "########## Concatenate Data ##########\n",
    "print(\"************************* Concatenating raws *************************\")\n",
    "raw = concatenate_raw_obj(raws,on_mismatch='warn')\n",
    "\n",
    "########## Create Events, Epochs, and Evoked Data ##########\n",
    "events = make_event(raw)\n",
    "epochs = epoch_data(events,raw)\n",
    "\n",
    "epochs['all'].save(meg_path+'\\\\'+epoched_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaf627b-a686-42d2-be35-f95c4602a6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Make Coregistration (GUI) ########## \n",
    "set_path(subj)\n",
    "make_coregistration_gui(meg_path+'\\\\'+epoched_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ef6ac3-0695-4fd3-bf44-dc50b88532d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Make Coregistration (Automatic) ##########\n",
    "set_path(subj)\n",
    "make_coregistration_automatic(meg_path+'\\\\'+epoched_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda5a2e3-918b-4d90-9351-813f2feff19f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "########## Make Source Localization ##########\n",
    "noise_cov_type = \"baseline\"   #\"baseline\", \"empty\"\n",
    "\n",
    "subject_list = ['Subj02','Subj03','subj04','Subj05','Subj09','Subj11',\n",
    "                'Subj12','Subj13','Subj14','Subj15','Subj16','Subj17',\n",
    "                'Subj18','Subj19','Subj20','Subj22','Subj23','Subj24',\n",
    "                'Subj26','Subj27','Subj28','Subj29','Subj30','Subj31',\n",
    "                'Subj32','Subj34','Subj36','Subj37','Subj38','Subj39',\n",
    "                'Subj40','Subj42']\n",
    "\n",
    "for subj in subject_list:\n",
    "    set_path(subj)\n",
    "    subject_info = import_info()\n",
    "    \n",
    "    path = os.path.join(meg_path,epoched_fname)\n",
    "    epochs = mne.read_epochs(path,preload=False)\n",
    "\n",
    "    if not os.path.exists(volume_path): os.makedirs(volume_path)\n",
    "    if noise_cov_type == \"empty\": noise_cov = read_cov_empty(subject_info)\n",
    "    \n",
    "    for e in event_sample_list:\n",
    "        if noise_cov_type == \"baseline\": noise_cov = make_cov_baseline(figure_path,e,epochs)\n",
    "        \n",
    "        stc, src = make_source_localization(epochs[e],epochs[e].average(),noise_cov)\n",
    "        stc.save(volume_path+'\\\\'+f\"{e}{tail_fname}\")\n",
    "        mne.write_source_spaces(volume_path+'\\\\'+f\"{e}{tail_fname}-src.fif\",src)\n",
    "        #save_surface_src_volume(stc, subject='freesurfer', subjects_dir=mri_folder, time_downsample_factor= 20, save_file_name=volume_path+'\\\\'+f\"stc_{e}.nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b920771-74a7-408d-ab5b-026585f84342",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Visualize Source Localization ########## \n",
    "stc = mne.read_source_estimate(volume_path+'\\\\'+'N1S1TFA1'+tail_fname, subject='freesurfer')\n",
    "visualize_source_localization(stc,'rh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e553e775-293f-40c7-8293-8944f646eaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Visualize Source Localization (Morph) ########## \n",
    "stc = mne.read_source_estimate(meg_path+'\\\\'+'N4S4TFA2', subject='freesurfer')\n",
    "visualize_source_localization_morph(stc,'rh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4358115-8861-48cf-87b7-b54715d0c3b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
